flask_app_code: |
  from flask import Flask, request, jsonify
  import numpy as np
  from tensorflow.keras.models import load_model
  import base64
  import cv2
  import numpy as np
  import io
  from PIL import Image

  app = Flask(__name__)

  # Load the pre-trained model
  model = load_model('exercise_classifier_model.h5')

  # Define classes for exercise classification
  classes = ['class1', 'class2', 'class3']  # Add your classes here

  def preprocess_image(img):
      # Preprocess the image (resize, normalize, etc.)
      # Here, we resize the image to match the input shape of the model
      img = cv2.resize(img, (224, 224))
      img = img / 255.0  # Normalize pixel values to [0, 1]
      return img

  @app.route('/classify', methods=['POST'])
  def classify():
      # Get the base64 encoded image data from the request
      data_url = request.json['image']

      # Extract the base64 encoded image data
      img_data = base64.b64decode(data_url.split(',')[1])

      # Convert the image data to a numpy array
      img = np.array(Image.open(io.BytesIO(img_data)))

      # Preprocess the image
      img = preprocess_image(img)

      # Expand dimensions to match the model's input shape (batch size = 1)
      img = np.expand_dims(img, axis=0)

      # Make prediction
      prediction = model.predict(img)

      # Get the predicted class label
      predicted_class = np.argmax(prediction)
      class_label = classes[predicted_class]

      # Return the prediction
      return jsonify({'prediction': class_label})

  if __name__ == '__main__':
      app.run(debug=True)

index_html_code: |
  <!DOCTYPE html>
  <html>
  <head>
      <title>Exercise Classification</title>
  </head>
  <body>
      <h1>Exercise Classification</h1>
      <video id="video" width="640" height="480" autoplay></video>
      <button id="captureButton">Capture</button>
      <canvas id="canvas" style="display:none;"></canvas>

      <script>
          // Get the video element
          const video = document.getElementById('video');

          // Get the canvas element
          const canvas = document.getElementById('canvas');
          const context = canvas.getContext('2d');

          // Get the capture button
          const captureButton = document.getElementById('captureButton');

          // Constraints for the webcam stream
          const constraints = {
              video: true
          };

          // Function to start the webcam
          async function startWebcam() {
              try {
                  // Get the webcam stream
                  const stream = await navigator.mediaDevices.getUserMedia(constraints);
                  video.srcObject = stream;
              } catch (err) {
                  console.error('Error accessing webcam:', err);
              }
          }

          // Function to capture an image from the webcam
          function captureImage() {
              // Draw the current frame from the webcam onto the canvas
              context.drawImage(video, 0, 0, canvas.width, canvas.height);

              // Get the base64 encoded image data from the canvas
              const imageData = canvas.toDataURL('image/jpeg');

              // Send the captured image data to the Flask backend for classification
              fetch('/classify', {
                  method: 'POST',
                  headers: {
                      'Content-Type': 'application/json'
                  },
                  body: JSON.stringify({ image: imageData })
              })
              .then(response => response.json())
              .then(data => {
                  console.log('Prediction:', data.prediction);
                  // Display the prediction in the console or update the UI as needed
              })
              .catch(error => console.error('Error:', error));
          }

          // Start the webcam when the page loads
          startWebcam();

          // Add event listener to the capture button
          captureButton.addEventListener('click', captureImage);
      </script>
  </body>
  </html>
